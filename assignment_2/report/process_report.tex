%\documentclass[english, a4paper]{article}
\documentclass{llncs}
\usepackage{llncsdoc}

\usepackage{float}
\usepackage[pdftex]{graphicx}
\usepackage[font={small,it}]{caption}
\usepackage[caption=false]{subfig}
\usepackage{url}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{pbox}
\usepackage{placeins}

\newcommand{\squeezeup}{\vspace{-8.9mm}}
\setcounter{secnumdepth}{3}
\addtolength{\textfloatsep}{-3mm}
\addtolength{\belowcaptionskip}{-15pt}



\title{Data Mining -- Assignment 2 Process Report}

\author{Andrew Bedard (2566978) -- Artagan Malsagov (2562231)  -- Shabaz Sultan(2566703)}

\institute{}
\begin{document}
\maketitle
\section{Schedule Overview}
We started working on the assignment in the week of April 20th. In that week each of us spend time looking at the assignment and the dataset to get a rough sense of it and what was expected. It was important that each of us individually had a sense of the type of data attributes in the dataset and the expected prediction. Each of us getting to the point of loading up the dataset in a dataexploration or machine learning environement and seeing what roadbloacks this type of `hello world' task\footnote{Besides an initial teaching example, Hello World programs can also be used as initial environement verification tasks, see \url{http://en.wikipedia.org/wiki/"Hello,_World!"_program}} would throw up was also part of this week.\\
The week of April 27th we met up again to discuss the major issues encountered in the first week and to make an intitial task division amongst the three of us. The major issue encountered in the first week was that the size of the dataset was big enough to be unwieldy. We had made a preliminary technology decision to use Python for most of the assignment; Pandas for data loading and manipulation and SciKit Learn for machine learning. Andrew had written an initial program in python to sample a subset of the data in Python, but this was still very slow. After this Shabaz wrote a faster program in C++ that could sample a subset of the training data and dump it into a new CSV file that could then be read into Python.\\
In this week we decided to task Andrew with data exploration, which he initial did in R and later in Python. Artagan was tasked with doing a literature study and look at what was out there in terms of presentations and papers by high scorers in the Kaggle competition. Shabaz looked at getting an initial program going that could load up the data and make some predicitions in Python code.\\
In the week of 4th of April we met again to talk on what we actually wanted to build for our final prediction. We had noticed that a lot of high scoring teams ended up using some sort of ensemble methods. In the meeting we had this week we decided on splitting up one paper or competitor presentation per person and have each team member try to replicate the approach for a week. In the final week we could then try to somehow blend the models if we end up with three viable models during this week. We figured this was a way to both get a prediction and force each member of our team to get plenty of hands on experience.\\
The final week before the prediction deadline, the week of April 11th, we each spend up finishing up our attempts of replicating the existing approaches to the problem. Shabaz tried to replicate the Commendo team's approach\cite{Jahrer2013}, Andrew looked at replicating some of the approaches in a paper describing an ensemble of methods\cite{Liu2013} and Artagan implemented the approach of the second place finishers\cite{Wang2013}.\\
The week of April 18th was spend with finishing up the report. Everybody wrote the section of the report describing their own approach. In addition Artagan wrote the intro and literature section, Andrew the data exploration part and Shabaz the result section.
\section{Reflection}
There are two major choices in our process that deserve examination. The first is that we proceeded in a fairly `waterfall model' type of process. All the research we tried to put up front, then do all the development work and only at the very end could we test, find bugs and tweak to improve. Instead the Agile family of methodologies would suggest us working in a more iterative manner, where each iteration would result in a complete back-to-front testable system.\\
We could have forced ourselves to make e.g. a full workable system at the end of each week even if we hadn't completely finished our literature research yet and even if our data exploration hadn't been completely exhaustive. This would have given us earlier feedback on what was working or not and possibly indications with which approaches might be more fruitful.\\
The second big process level decision we made was to split up the development work in three mostly separate parts and have everyone work on development. It would've possibly been more productive to only work on one model and to have the bulk of the work done by one person. Possible this could've resulted in a higher scoring model. There is a secondary goal to this project for us however, which is that we wanted every one of our team members to get plenty of hands on experience.\\
We are a team consisting of a mathematician (Andrew), an econometrician (Artagan) and a computer scientist (Shabaz). We were very keen to avoid one person inadvertently taking on all the development work and inadvertently removing the opportunity to learn for the other team members. Making sure everybody tried to implement their own model (with plenty of cooperation while developing) felt like a good way to reach this goal.
\bibliographystyle{plain}
\bibliography{process_report}
\end{document}
