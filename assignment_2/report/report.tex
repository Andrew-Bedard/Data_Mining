%\documentclass[english, a4paper]{article}
\documentclass{llncs}
\usepackage{llncsdoc}

\usepackage{float}
\usepackage[pdftex]{graphicx}
\usepackage[font={small,it}]{caption}
\usepackage[caption=false]{subfig}
\usepackage{url}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{pbox}
\usepackage{placeins}

\newcommand{\squeezeup}{\vspace{-8.9mm}}
\setcounter{secnumdepth}{3}
\addtolength{\textfloatsep}{-3mm}
\addtolength{\belowcaptionskip}{-15pt}



\title{Data Mining -- Assignment 2}

\author{Andrew Bedard (2566978) -- Artagan Malsagov (2562231)  -- Shabaz Sultan(2566703)}

\institute{}
\begin{document}
\maketitle
\section{Introduction}
The online travel agency (OTA) Expedia posed the challenge to rank hotels by their likelihood of being booked. In such a competitive market as the one of click-through purchases, properly ranking offered hotels according to user's preferences becomes indispensable for the OTA to win the sale. This requires an algorithm that can rank the hotels associated with a user search query. The use of ranking algorithms in the industry of online travel booking is uncharted territory and the challenge provided opportunities to explore. For further information on the competition see the Kaggle platform \cite{WinNT}.

This report details our approach to tackling this problem based on the search and click-through data provided by Expedia. First, a short review of the available literature on the topic is given. Then a description of the data and the task at hand is provided. This is followed up by a review of the methods and models used by us and how they held up to the challenge. Finally, we finish off with a summary and some concluding remarks.  

\section{Related work}
Here is a sample of the approaches of some of the groups that participated in the Expedia challenge. 

Let's start with the official winner of the competition, whose approach can be found in \cite{WinNT2}. For the feature engineering missing values were said to be imputed by negative values, which we believe to mean the worst case is assumed. The rationale being customers don't like to book hotels with missing values. Numerical variables were bounded to remove outliers. Negative instances of booking and clicking were down-sampled. All original features were used, plus engineered features such as averages of numerical variables, price difference and categorical features converted to numerical ones. As a model an ensemble of Gradient Boosting Machines was used. 

The official runner-up also did a lot of feature engineering. Missing values were replaced by worst-case scenarios by the same reasoning as above. For instance the missing values of competitor descriptions where replaced by zero, which means data is not available. Furthermore, certain numerical features were normalized with respect to different indicators such as the prop\_id, srch\_id and month. New features were constructed such as the difference between the visitor's starrating and the starrating given to a certain property. This gave a total of 300 features on which the models LambdaMART, SVM Rank and linear regression were used. The final model used was LambdaMART. An import aspect of LambdaMART for this problem is that it can maximize non-smooth information retrieval function such as NDCG@k, which was used as an evalutation metric in this competition.

The paper \cite{DBLP:journals/corr/LiuXZYPLSW13} details an approach which meshes together several different ranking models: logistic regression, support vector machines, random forest, gradient boosting machine, factorization machine and LambdaMART, among others. The team identified the most import features as price\_usd, prop\_starrating and prop\_location\_score2. Data was balanced for training random forest, making it feasible to train with a large number of trees.  For missing values the first quartile calculated for the prop\_id of the missing data point was used. As their ensemble the team tried different linear combinations and sought the combination that would give a better result than a single model could.
 
\section{Data description}
Given a search query $x_{i}$ and the hotels $\{h_{1}^{i},\dots,h_{m_{i}}^{i}\}$ associated with it, where $\leq m_{i} \leq 38$(the maximum number of hotels associated with any search query is not more than $38$ and not less than $4$), a ranking algorithm has to estimate the scores  $\{s_{1}^{i},\dots,s_{m_{i}}^{i}\}$ corresponding to these hotel. The scores are assigned as:
$$
s_{j}^{i}=
\left\{
	\begin{array}{ll}
		5  & \mbox{if hotel $j$ was booked }   \\
		1 & \mbox{if hotel $j$ was clicked }  \\
		0 & \mbox{if hotel $j$ was neither clicked nor booked}
	\end{array}
\right.
$$
  
The data taken from Kaggle totals about $10$ million records spanned by $336,334$ search queries, meaning at least $4$ records correspond to one search query and at most $38$. The data is divided in half into a training and test set. Each record in the training data is represented by $54$-dimensional vector, where the two class variables booking and clicking and the variables for purchase amount and position in Expedia's ranked list are not included in the test set. Indeed, in our problem the target variables to be estimated are click\_bool and book\_boolean, based on which the scores for the ranking can be assigned. The remaining $50$ variables are roughly divided into search criteria, hotel characteristics (dynamic/static), history of the user and competitive OTA information. A variable not covered by these categories is whether the search result were presented in random order or based on the ranking algorithm employed by Expedia (in some cases hotels were presented in random order to learn about user preferences).

As an evaluation metric the average NDCG over all queries is used, with $k=38$ as the truncation level. Formally, $\displaystyle DCG_{k}=\sum_{i=1}^{k}\frac{2^{rel_i}-1}{\log_{2}(i+1)}$. Here $rel_{i}$ represent the true score of the hotel ranked in position $i$. Observe that only one score can be $5$: the hotel booked. The further down the summation it is placed the more it is discounted, decreasing the score. Likewise for the hotels that were clicked and it doesn't matter in which order the clicks are placed, as long as they are ranked below the booked hotel and above the hotels booked nor clicked. The ideal ranking then gives the maximal discounted gain, $IDCG_{k}$. Consequently, $NDCG_{k}=\frac{DCG_{k}}{IDCG_{k}}$ 

\subsection{Some challenges and observations}
Some reflections on the challenges with the data and problem are in order. First, the size of the dataset is impractical for training purposes and most software might choke on it. An appropriate technique has to be used to sample a representative subset of the data.

What's more, the data is unbalanced: at most one hotel can be booked and only a few get usually clicked, meaning it might be tempting for the algorithm to always predict not booked and not clicked. Depending on the algorithm,this situation can be remedied by down-sampling the negative instances.

The data is raw and not manually checked. So another hassle concerns missing data and outliers, which has to be dealt with when training. 

The data is furthermore divided into categorical and numerical variables. The categorical variables are for instance IDs for the search queries, hotels and websites of Expedia.  

Finally, there are multiple output variables, which can be represented in different ways, namely as either a score or classes for clicks and bookings. The fact is also that the NDCG is not a smooth function of the scores, which makes it hard to involve it in an online optimization process.            

\section{Working on the data}
\textit{price\_ usd} had many outliers, these were replaced with the first quantile value, missing values in \textit{prop\_ location\_ score2, visitor\_ hist\_ adr\_ usd, visitor\_ hist\_ starrating, prop\_ review\_ score} were replaced with the mean values of each property within their country id. Zero values in \textit{prop\_ starrating, prop\_ review\_ score, prop\_ starrating} were replaced with the third quantile values within their country id. Zero values in \textit{prop\_ log\_ historical\_ price} were replaced by first quantile values. Zero values of \textit{srch\_ length\_ of\_ stay} were replaced with mean within country id.

\[\textit{ump = exp(prop\_ log\_ historical\_ price) - price\_ usd}\]
\[\textit{price\_ diff = visitor\_ hist\_ adr\_ usd - price\_ usd}\]
\[\textit{starrating\_ diff = visitor\_ hist\_ starrating - prop\_ starrating}\]
\[\textit{per\_ fee} = \frac{\textit{price\_ usd*srch\_ room\_ count}}{\textit{srch\_ adults\_ count+srch\_ children\_ count}}\]
\[\textit{score2ma = prop\_ location\_ score2*srch\_ query\_ affinity\_ score}\]
\[\textit{total\_ fee = price\_ usd*srch\_ room\_ count}\]
\[ \textit{score1d2} = \frac{\textit{prop\_ location\_ score2} + 0.0001}{\textit{prop\_ location\_ score1} + 0.0001}\]

Mostly Andy stuff.
Feature engineering and reasoning behind it.


\section{Models and evaluation}

\subsection{Monotonic utility of the variables and SVM/GBM}
This approach was heavily inspired by the presentation of the official runner-up of the competition (see \cite{WinNT2}), where among other things RankSVM was used. This methods usually relies on linear separability, so the feature engineering we want to perform should reflect.

Let's start with an obviously important variable, the price of the hotels and take the log of it. This move accentuates the linearity between the price and the target variables, because log transform result in percentage changes and this way changes at higher levels of price are not wildly different from changes at lower levels of price. This is in line with the linear requirements of SVM. In this approach the $\log_{10}$ was taken, so as to keep the engineered variable within a workable range.

A central argument in the feature engineering of the runner-up was creating variables with monotonic utility with respect to the target variables, in particular a variable that is non-increasing with respect to clicks and bookings. So as the variable increases the number of hotels clicked/booked for that variable decreases. This property comes in handy for ranking with SVM because the larger a variable for a certain hotel, the less likely that hotel is to be booked or clicked. So when training the ranking algorithm, there is a way to separate hotels that are likely to be booked from those that are not because of variables with monotonic utility.

For instance, the variable representing the star rating of the hotels does not have this monotonic utility property, as can be seen from the figure below :
 \begin{figure}[H]
     \centering
     \includegraphics[width=\linewidth, height=155px]{figure_normal_starrate.png}
     \caption{Percentage of booked hotels per starrating values}
     \label{fig:prop_starrating}
 \end{figure}
\noindent However, through a simple operation a new feature can be constructed with the desired property: 
$$
\textit{prop\_starrating\_monotonic} = |\textit{prop\_starrating} -\textit{mean(prop\_starrating[booking\_bool])}|
$$
where the mean of the star-ratings of all booked hotels is subtracted from the regular variable \textit{prop\_starrating}, of which the absolute value is then taken. The intuition here is that the more a hotel star-rating deviates from the mean star-rating of the booked hotels, the less it is booked. Plotting a similar bar chart as the one above corroborates this intuition:
 \begin{figure}[H]
     \centering
     \includegraphics[width=\linewidth, height=155px]{figure_monotonic_starrate.png}
     \caption{Percentage of booked hotels per feature engineered starrating values}
     \label{fig:prop_starrating}
 \end{figure}

\subsection*{Andy}


\pagebreak
\subsection{Commendo team approach}
The highest scoring team in the Kaggle competition was the Commendo team, part of the Opera Solutions company. They however were not granted the first place prize. We speculate that they were unwilling or unable to fully disclose their approach to Kaggle and Expedia because of use of internal tools and code that they wished to remain proprietary\footnote{A Kaggle competition admin states ``The commendo team (Michael Jahrer) achieved the highest score but was not able to fulfil all the contest requirements.'', see \url{https://www.kaggle.com/c/expedia-personalized-sort/forums/t/6203/winning-algorithm/49840#post49840}}. This made replicating their approach challenging, with only a minimal presentation to go by\cite{Jahrer2013}.\\
The approach talks about training on 19 numerical variables. We have interpreted this as being the following parameters:\\
\verb!'visitor_hist_starrating'!, \verb!'visitor_hist_adr_usd'!, \verb!'prop_starrating'!, \verb!'prop_review_score'!, \verb!'prop_brand_bool'!, \verb!'prop_location_score1'!, \verb!'prop_location_score2'!, \verb!'prop_log_historical_price'!, \verb!'price_usd'!, \verb!'promotion_flag'!, \verb!'srch_length_of_stay'!, \verb!'srch_booking_window'!, \verb!'srch_adults_count'!, \verb!'srch_children_count'!, \verb!'srch_room_count'!, \verb!'srch_saturday_night_bool'!, \verb!'srch_query_affinity_score'!, \verb!'orig_destination_distance'!, \verb!'random_bool'!. \\
The other attributes that were excluded were mostly categorical variables. The other approaches do a fair amount of feature engineering with aggregate values calculated using said categorical variables. We felt this was a good way to see how far an approach could get with more direct training on the existing numerical variables. Especially since the high score claimed to have directly trained on these and gotten very high scores using multiple different approaches.\\
During developement instead of using the full training set a subset of 10\% was loaded. The subset was generated by a C++ program that would either select all records of a certain search id or none. This 10\% subset would then be split up again, 90\% of it in a training set and 10\% in a test set (i.e. 9\% of the original training set is trained on, 1\% to test). Again during splitting records with the same search id stick together.\\
It is not specified exactly what is trained. We implemented two binary classifiers to predict clicking and booking behaviour for each of the records in the dataset. Possibly a regression model that directly tries to predict the score would've been more accurate, but was also much slower to train so wasn't used during development. This would however be one of the first things to be looked at when doing further development on this model.\\
It is also not specified exactly how empty positions in the dataset are filled in. We opted to just use the mean of an attribute to fill in empty positions.\\
When training the classifiers using a stochastic gradient descent (SGD) learned linear classifier we get a score of \textbf{0.349}. When using a gradient boosting classifiers we also get a score of \textbf{0.349}. These are score comparable with pure random sorting. \\
One thing we noticed during exploration is that the dataset is very much biased towards negative instances, i.e. records where no clicking or booking occurs. When training classifiers this means that they very much want to just always predict the negative case, because this results in pretty high accuracy. To mitigate this we undersample the negative instance. When training the classifier that predicts the booking boolean we select all records with a booking and then select a subset of the non-booking records that is equal in size to the set of booking records. We do the same with clicking classifier.\\
Now with the trainingsets with undersampled negative instances we still get a score of \textbf{0.345} for the SGD classifiers. The gradient boosting classifiers however get a score of \textbf{0.392}. This is not terribly high, but is at least discernibly higher than a random score.\\
The Commendo team also talks about adding aggregate values to the dataset, where we group on the \verb!prop_id! and  calculate mean, median and standard deviation for each of the numerical attributes they train on. When we add all these aggregate attributes the number of attributes are so high that the system cannot train on it and always give a score equivalent to random.\\
Instead we added aggregate variables based on only one of the numerical attributes at a time. This also results in scores that don't go above 0.36. We have tried training with undersampling and not undersampling negative instances.
\bibliographystyle{plain}
\bibliography{report}
\end{document}
