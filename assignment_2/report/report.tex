%\documentclass[english, a4paper]{article}
\documentclass{llncs}
\usepackage{llncsdoc}

\usepackage{float}
\usepackage[pdftex]{graphicx}
\usepackage[font={small,it}]{caption}
\usepackage[caption=false]{subfig}
\usepackage{url}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{pbox}
\usepackage{placeins}

\newcommand{\squeezeup}{\vspace{-8.9mm}}
\setcounter{secnumdepth}{3}
\addtolength{\textfloatsep}{-3mm}
\addtolength{\belowcaptionskip}{-15pt}



\title{Data Mining -- Assignment 2}

\author{Andrew Bedard (2566978) -- Artagan Malsagov (2562231)  -- Shabaz Sultan(2566703)}

\institute{}
\begin{document}
\maketitle
\section{Introduction}
The online travel agency (OTA) Expedia posed the challenge to rank hotels by their likelihood of being booked. In such a competitive market as the one of click-through purchases, properly ranking offered hotels according to user's preferences becomes indispensable for the OTA to win the sale. See the Kaggle platform \cite{WinNT} for further information on the competition.

This report details our approach to tackling this problem based on the search and click-through data provided by Expedia. First, a short review of the available literature on the topic is given. Then a description of the data is provided and the problem is defined in more rigorous terms. This is followed up by a review of the methods and models used by us and how they held up to the challenge. Finally, we finish off with a summary and some concluding remarks.  

\section{Related work}
The use of ranking algorithms in the industry of online travel booking is relatively new. Here is a sample of the approaches of some of the groups that particaped in the Kaggle challenge.

Let's start with the official winner of the competition, whose approach was detailed in a slide set on Kaggle. For the feauture engineering missing values were imputed by negative values, the rationale behind it being that if a value is missing, the worst case can be assumed. Numerical variables were bounded to remove outliers. Negative instances of booking and clicking were downsampled. All original features were used, plus engineered features such as averages of numerical variables, price difference and categorical features converted to numerical ones. As a model an ensemble of Gradient Boosting Machines were used. 

The official runner-up also did a lot of feature engineering. Missing values were replaced by worst-case scenario, since customers probably don't like to book hotels with missing values. For instance the missing values of competitor where replaced by zero. Furthermore, certain numerical features were normalized with respect to different indicators such as the prop\_id, srch\_id and month. New features were constructed such as the difference between the visitor's starrating and the starrating given to a certain property. This gave a total of 300 features on which the models LambdaMART, SVM Rank and linear regression were used. The final model was LambdaMART.

The paper *reference here* detail an approach which meshes together several different ranking models: logistic regression, support vector machines, random forest, gradient boosting machine, factorization machine and LambdaMART, among others. The team identified the most import features as price\_usd, prop\_starrating and prop\_location\_score2. For missing values the first quartile calculated for the prop\_id of the missing data point was used. As their ensemble the team tried different linear combinations and sought the combination that would give a better result than one of the single models could.  

 
\section{Data description}

Salient features of the data, Couple of graphs, percentage of data missing etc...

\section{Working on the data}

\textit{price\_ usd} had many outliers, these were replaced with the first quantile value, missing values in \textit{prop\_ location\_ score2, visitor\_ hist\_ adr\_ usd, visitor\_ hist\_ starrating, prop\_ review\_ score} were replaced with the mean values of each property within their country id. Zero values in \textit{prop\_ starrating, prop\_ review\_ score, prop\_ starrating} were replaced with the third quantile values within their country id. Zero values in \textit{prop\_ log\_ historical\_ price} were replaced by first quantile values. Zero values of \textit{srch\_ length\_ of\_ stay} were replaced with mean within country id.

\[\textit{ump = exp(prop\_ log\_ historical\_ price) - price\_ usd}\]
\[\textit{price\_ diff = visitor\_ hist\_ adr\_ usd - price\_ usd}\]
\[\textit{starrating\_ diff = visitor\_ hist\_ starrating - prop\_ starrating}\]
\[\textit{per\_ fee} = \frac{\textit{price\_ usd*srch\_ room\_ count}}{\textit{srch\_ adults\_ count+srch\_ children\_ count}}\]
\[\textit{score2ma = prop\_ location\_ score2*srch\_ query\_ affinity\_ score}\]
\[\textit{total\_ fee = price\_ usd*srch\_ room\_ count}\]
\[ \textit{score1d2} = \frac{\textit{prop\_ location\_ score2} + 0.0001}{\textit{prop\_ location\_ score1} + 0.0001}\]

Mostly Andy stuff.
Feature engineering and reasoning behind it.


\section{Models and evaluation}

\subsection*{Artagan}

\subsection*{Andy}



\subsubsection*{Mr. Get'er done}


          
\bibliographystyle{plain}
\bibliography{report}
\end{document}
